{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Proyecto Open Data I\n",
    "## Radares, y su eficiencia en la CAM\n",
    "### Recopilación, limpieza y tratamiento de los datos\n",
    "Este cuaderno pretende enseñar el proceso de limpieza de los datos relativos a los radares en la CAM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "403b90b536e46321"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import os\n",
    "\n",
    "import pandas\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T15:51:45.211752200Z",
     "start_time": "2023-10-26T15:51:44.433425300Z"
    }
   },
   "id": "b49b58b0e667e6db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación, se muestra la clase que está compuesta de todos los métodos que se encargan de la limpieza y transformación de los datos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1aa1793c05e1e91"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class CSVDataLoader:\n",
    "    \"\"\"\n",
    "    A class for loading and cleaning CSV data from a specified folder path.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    folder_path : str\n",
    "        The path to the folder containing the CSV files to be loaded.\n",
    "\n",
    "    data : dict\n",
    "        A dictionary containing the loaded CSV data, where the keys are the file names and the values are the corresponding dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder_path):\n",
    "        \"\"\"\n",
    "        Initializes a CSVDataLoader object with the specified folder path.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        folder_path : str\n",
    "            The path to the folder containing the CSV files to be loaded.\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        self.data = {}\n",
    "        self.filename = []\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads CSV data from the specified folder path into a dictionary.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        csv_files = [f for f in os.listdir(self.folder_path) if f.endswith('.csv')]\n",
    "        folders = (\"datasets/actuacionesBomberos\", \"datasets/estaciones\", \"datasets/accidentalidad\")\n",
    "        for folder in folders:\n",
    "            df = None\n",
    "            for file in os.listdir(folder):\n",
    "                filepath = folder + \"/\" + file\n",
    "                df1 = pd.read_csv(filepath, sep=';', encoding='utf-8', low_memory=False)\n",
    "                df = pd.concat([df, df1])\n",
    "            self.data[str(folder)] = df\n",
    "\n",
    "        for file_name in csv_files:\n",
    "            file_path = os.path.join(self.folder_path, file_name)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=';', encoding='latin-1', low_memory=False)\n",
    "                self.data[str(file_name)] = df\n",
    "                self.filename.append(file_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al leer {file_name}: {str(e)}\")\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        Cleans the loaded CSV data by renaming columns, removing whitespace, dropping null values and duplicates, and converting date columns to datetime format.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None\n",
    "        \"\"\"\n",
    "        for i in self.data:\n",
    "            num_columnas = self.data[i].shape[1] -1\n",
    "            columna_borrar = \"Unnamed: \" + str(num_columnas)\n",
    "\n",
    "            if columna_borrar in self.data[i].columns:\n",
    "                self.data[i] = self.data[i].drop(columna_borrar, axis=1)\n",
    "                self.data[i] = self.data[i].dropna()\n",
    "\n",
    "            self.data[i] = self.data[i].rename(columns = lambda x: x.strip().lower().replace(' ', '_'))\n",
    "            self.data[i] = self.data[i].applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "            self.data[i] = self.data[i].dropna()\n",
    "            self.data[i] = self.data[i].drop_duplicates()\n",
    "            self.data[i] = self.data[i].loc[:, ~self.data[i].columns.duplicated()]\n",
    "            self.data[i].columns = pd.DataFrame.applymap(str.upper, self.data[i].columns)\n",
    "\n",
    "            if 'FECHA' in self.data[i].columns:\n",
    "                self.data[i]['FECHA'] = pd.to_datetime(self.data[i]['FECHA'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "    def get_nan_columns(self):\n",
    "        for i in self.data:\n",
    "            print(self.data[i].isnull().sum())\n",
    "            print(self.data[i].info())\n",
    "    def get_cleaned_data(self):\n",
    "        \"\"\"\n",
    "        Returns the cleaned CSV data as a dictionary.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            A dictionary containing the cleaned CSV data, where the keys are the file names and the values are the corresponding dataframes.\n",
    "        \"\"\"\n",
    "        return self.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T15:55:05.172376400Z",
     "start_time": "2023-10-26T15:55:05.140953300Z"
    }
   },
   "id": "256fe2dfa6c0c984"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez está definida la clase con sus métodos, procedemos a declarar las variables que nos permiten trabajar con ello"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd3a99e7c5630daf"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "folder_path = \"datasets\"\n",
    "data_loader = CSVDataLoader(folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T15:55:09.279618300Z",
     "start_time": "2023-10-26T15:55:09.270337700Z"
    }
   },
   "id": "9e988a29148b801d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data_loader.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T15:55:13.128379800Z",
     "start_time": "2023-10-26T15:55:09.722915900Z"
    }
   },
   "id": "f5f8f909f38d9d3d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_27168\\1255346888.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdata_loader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclean_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_27168\\1681665793.py\u001B[0m in \u001B[0;36mclean_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     73\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop_duplicates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m~\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mduplicated\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapplymap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupper\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;34m'FECHA'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mapplymap\u001B[1;34m(self, func, na_action, **kwargs)\u001B[0m\n\u001B[0;32m   8923\u001B[0m             )\n\u001B[0;32m   8924\u001B[0m         \u001B[0mignore_na\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mna_action\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 8925\u001B[1;33m         \u001B[0mfunc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunctools\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpartial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   8926\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   8927\u001B[0m         \u001B[1;31m# if we have a dtype == 'M8[ns]', provide boxed values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "data_loader.clean_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T15:55:13.170093100Z",
     "start_time": "2023-10-26T15:55:13.128379800Z"
    }
   },
   "id": "d0efeb80b7d4f3b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "840ef0fe4c601475"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
